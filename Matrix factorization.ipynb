{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Matrix factorization.ipynb","provenance":[],"authorship_tag":"ABX9TyNRulxXqOWIBK/MCAXTBy3O"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["pip install pyspark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hnr4TQItke64","executionInfo":{"status":"ok","timestamp":1654830324580,"user_tz":-330,"elapsed":53577,"user":{"displayName":"ASHWIN SATHISH KUMAR","userId":"16573036374703807472"}},"outputId":"e2867917-e19d-4c74-b106-bb2b38cd5288"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyspark\n","  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n","\u001b[K     |████████████████████████████████| 281.4 MB 32 kB/s \n","\u001b[?25hCollecting py4j==0.10.9.3\n","  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n","\u001b[K     |████████████████████████████████| 198 kB 31.7 MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=86c823e36a440b5e70bf3e8c4a8a5ad59b319738414cb97dc41d0d425f6e27d3\n","  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n","Successfully built pyspark\n","Installing collected packages: py4j, pyspark\n","Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"]}]},{"cell_type":"code","source":["import pyspark"],"metadata":{"id":"212m1Al-ku02","executionInfo":{"status":"ok","timestamp":1654830342920,"user_tz":-330,"elapsed":8,"user":{"displayName":"ASHWIN SATHISH KUMAR","userId":"16573036374703807472"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"id":"VGOOxh75ek68","executionInfo":{"status":"ok","timestamp":1654830402463,"user_tz":-330,"elapsed":387,"user":{"displayName":"ASHWIN SATHISH KUMAR","userId":"16573036374703807472"}}},"outputs":[],"source":["from pyspark.ml.recommendation import ALS\n","\n","\n","def tune_ALS(train_data, validation_data, maxIter, regParams, ranks):\n","\n","    min_error = float('inf')\n","    best_rank = -1\n","    best_regularization = 0\n","    best_model = None\n","    for rank in ranks:\n","        for reg in regParams:\n","        \n","            als = ALS().setMaxIter(maxIter).setRank(rank).setRegParam(reg)\n","            model = als.fit(train_data)\n","            \n","            predictions = model.transform(validation_data)\n","            evaluator = RegressionEvaluator(metricName=\"rmse\",\n","                                            labelCol=\"rating\",\n","                                            predictionCol=\"prediction\")\n","            rmse = evaluator.evaluate(predictions)\n","            print('{} latent factors and regularization = {}: '\n","                  'validation RMSE is {}'.format(rank, reg, rmse))\n","            if rmse < min_error:\n","                min_error = rmse\n","                best_rank = rank\n","                best_regularization = reg\n","                best_model = model\n","    print('\\nThe best model has {} latent factors and '\n","          'regularization = {}'.format(best_rank, best_regularization))\n","    return best_model"]}]}