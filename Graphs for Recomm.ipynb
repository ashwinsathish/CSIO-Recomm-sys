{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Graphs for Recomm.ipynb","provenance":[],"authorship_tag":"ABX9TyPQhcss9R6YsyUnET/0fDkO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## graph.py"],"metadata":{"id":"9vNOgHbttxOO"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"uBY_9IBzrcUp","executionInfo":{"status":"ok","timestamp":1657958825382,"user_tz":-330,"elapsed":9,"user":{"displayName":"ASHWIN SATHISH KUMAR","userId":"16573036374703807472"}}},"outputs":[],"source":["import logging\n","import sys\n","from os import path\n","from time import time\n","from glob import glob\n","from six.moves import range, zip, zip_longest\n","from six import iterkeys\n","from collections import OrderedDict, defaultdict\n","from collections.abc import Iterable\n","from multiprocessing import cpu_count\n","import random\n","import collections\n","from random import shuffle\n","from itertools import product,permutations\n","from scipy.io import loadmat\n","from scipy.sparse import issparse\n","\n","from concurrent.futures import ProcessPoolExecutor\n","\n","from multiprocessing import Pool\n","from multiprocessing import cpu_count"]},{"cell_type":"code","source":["logger = logging.getLogger(\"deepwalk\")"],"metadata":{"id":"CiHULJpyrjnQ","executionInfo":{"status":"ok","timestamp":1657958857703,"user_tz":-330,"elapsed":913,"user":{"displayName":"ASHWIN SATHISH KUMAR","userId":"16573036374703807472"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["LOGFORMAT = \"%(asctime).19s %(levelname)s %(filename)s: %(lineno)s %(message)s\""],"metadata":{"id":"e-n-QqtGrjo6","executionInfo":{"status":"ok","timestamp":1657958860147,"user_tz":-330,"elapsed":6,"user":{"displayName":"ASHWIN SATHISH KUMAR","userId":"16573036374703807472"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["class Node(object):\n","    def __init__(self, id, name, type='user'):\n","        self.id = str(id) \n","        self.neighbors = []\n","        self.name = name\n","        self.type = type\n","        self.rating = {}\n","\n","class Movie(object):\n","    def __init__(self, name):\n","        self.name = name\n","        self.director = None\n","        self.actors = [] \n","        self.genres = []"],"metadata":{"id":"MnJ6TRymrjrB","executionInfo":{"status":"ok","timestamp":1657958866635,"user_tz":-330,"elapsed":8,"user":{"displayName":"ASHWIN SATHISH KUMAR","userId":"16573036374703807472"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["text = 'I am having lunch'\n","op = text.strip().split()[:2]\n","op"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"07-2J-s5E4A_","executionInfo":{"status":"ok","timestamp":1657959374703,"user_tz":-330,"elapsed":333,"user":{"displayName":"ASHWIN SATHISH KUMAR","userId":"16573036374703807472"}},"outputId":"8001b3b3-ddfe-4de6-df24-820ce107a899"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['I', 'am']"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["def load_movie_data():\n","    # Movie data files used for building the graph\n","    movies_directors_filename = \"movie_directors.dat\"\n","    movies_actors_filename = \"movie_actors.dat\"\n","    movies_genres_filename = \"movie_genres.dat\"\n","    movies_filename = \"movies.dat\"\n","    \n","    # Load the data about the movies into a dictionary\n","    # The dictionary maps a movie ID to a movie object\n","    # Also store the unique directors, actors, and genres\n","    \n","    movies = {} # a dictionary\n","    with open(movies_filename, \"r\", encoding = \"ISO-8859-1\") as fin:\n","        next(fin)  # burn metadata line\n","        for line in fin:\n","            m_id, name = line.strip().split()[:2] # since first 2 words depict id and name of movie in the dataset\n","            movies[\"m\"+m_id] = Movie(name)\n","    \n","    directors = set([]) # a set\n","    with open(movies_directors_filename, \"r\", encoding = \"ISO-8859-1\") as fin:\n","        next(fin)  # burn metadata line\n","        for line in fin:\n","            m_id, director = line.strip().split()[:2]\n","            if \"m\"+m_id in movies:\n","                movies[\"m\"+m_id].director = director\n","            directors.add(director)\n","    \n","    actors = set([])\n","    with open(movies_actors_filename, \"r\", encoding = \"ISO-8859-1\") as fin:\n","        next(fin)  # burn metadata line\n","        for line in fin:\n","            m_id, actor = line.strip().split()[:2]\n","            if \"m\"+m_id in movies:\n","                movies[\"m\"+m_id].actors.append(actor)\n","            actors.add(actor)\n","    \n","    genres = set([])\n","    with open(movies_genres_filename, \"r\", encoding = \"ISO-8859-1\") as fin:\n","        next(fin)  # burn metadata line\n","        for line in fin:\n","            m_id, genre = line.strip().split()\n","            if \"m\"+m_id in movies:\n","                movies[\"m\"+m_id].genres.append(genre)\n","            genres.add(genre)\n","\n","    return movies, directors, actors, genres"],"metadata":{"id":"l-qVpGk6rjtV","executionInfo":{"status":"ok","timestamp":1657961420226,"user_tz":-330,"elapsed":498,"user":{"displayName":"ASHWIN SATHISH KUMAR","userId":"16573036374703807472"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def records_to_graph():\n","    \"\"\"\n","    Creates a graph from the datasets (hardcoded).\n","\n","    A node is created for each entity: user, movie, director, genre, rating.\n","    The rating nodes created as one node for each possible 1-5 rating and for each movie.\n","        e.g., The movie 124 will lead to the nodes 124_1, 124_2, 124_3, 124_4, and 124_5.\n","\n","    Edges are added based on the datasets; e.g., actor a1 was in movie m1, so an edge is created between m1 and a1.\n","    The movie rating node 124_2, for example, will be connected to movie 124 and any users who rated 124 as a 2.\n","    \"\"\"\n","    \n","    # Output files for the graph\n","    adjlist_file = open(\"./out.adj\", 'w')\n","    node_list_file = open(\"./nodelist.txt\", 'w')\n","\n","    # Load all the ratings for every user into a dictionary\n","    # The dictionary maps a user to a list of (movie, rating) pairs\n","    # e.g., ratings[75] = [(3,1), (32,4.5), ...]\n","    num_ratings = 0\n","    ratings = collections.defaultdict(dict)\n","    with open(\"train_user_ratings.dat\", \"r\") as fin:\n","        next(fin)\n","        for line in fin:\n","            ls = line.strip().split(\"\\t\")\n","            user, movie, rating = ls[:3]\n","            rating = str(int(round(float(rating))))\n","            ratings[\"u\"+user][\"m\"+movie] = rating\n","            num_ratings += 1\n","    \n","    movies, directors, actors, genres = load_movie_data()\n","    \n","    \n","    # Create nodes for the different entities in the graph\n","    # Keep all the nodes that you make in nodelist.\n","    # nodedict should map node IDs to their respective node object.\n","    # The node IDs should be the ID of that node in the graph; the IDs need to range from 0 to n-1 incrementally.\n","    #   e.g., the node u75's ID may be 12 => nodedict[\"u75\"].id = 12\n","    nodelist = []\n","    nodedict = {}\n","\n","    count = 0\n","\n","    for key in movies.keys():\n","        node = Node(count, key, 'movie')\n","        nodelist.append(node)\n","        nodedict[key] = count\n","        count += 1\n","        i = 1\n","        while i <= 5 :\n","             value = str(key) + '_' + str(i)\n","             if value not in nodedict.keys():\n","                 node = Node(count, value, 'rating')\n","                 nodelist.append(node)\n","                 nodedict[value] = count\n","                 count += 1\n","             i += 1\n","\n","    for actor in actors:\n","        node = Node(count, key)\n","        nodelist.append(node)\n","        nodedict[actor] = count\n","        count += 1\n","    \n","    for genre in genres:\n","        node = Node(count, genre, 'genre')\n","        nodelist.append(node)\n","        nodedict[genre] = count\n","        count += 1\n","\n","    for director in directors:\n","        node = Node(count, director, 'director')\n","        nodelist.append(node)\n","        nodedict[director] = count            \n","        count += 1\n","\n","    for key in ratings.keys():\n","        node = Node(count, key)\n","        nodelist.append(node)\n","        nodedict[key] = count\n","        count += 1\n","\n","    # Add edges between users and movie-rating nodes\n","    # Add edges between movies and directors\n","    # Add edges between movies and actors\n","    # Add edges between movies and genres\n","    # Add edges between movie ratings and movies\n","    # By \"add an edge\" we mean to update the neighbors list of the nodes in both directions:\n","    #   e.g., \n","    #           director_node.neighbors.append(movie_node)\n","    #           movie_node.neighbors.append(director_node)\n","\n","\n","    for key in movies.keys():\n","        for actor in movies[key].actors:\n","            nodelist[int(nodedict[actor])].neighbors.append(nodelist[int(nodedict[key])])\n","            nodelist[int(nodedict[key])].neighbors.append(nodelist[int(nodedict[actor])])\n","        for genre in movies[key].genres:\n","            nodelist[int(nodedict[genre])].neighbors.append(nodelist[int(nodedict[key])])\n","            nodelist[int(nodedict[key])].neighbors.append(nodelist[int(nodedict[genre])])\n","        director = movies[key].director\n","        if director is not None:\n","            nodelist[int(nodedict[director])].neighbors.append(nodelist[int(nodedict[key])])\n","            nodelist[int(nodedict[key])].neighbors.append(nodelist[int(nodedict[director])])\n","        \n","    \n","    edges_added = []\n","\n","    for k in ratings.keys():\n","        for key in ratings[k].keys():\n","            value = str(key) + '_' + str(ratings[k][key])\n","            nodelist[int(nodedict[value])].neighbors.append(nodelist[int(nodedict[k])])\n","            nodelist[int(nodedict[k])]. neighbors.append(nodelist[int(nodedict[value])])\n","            if value in edges_added:\n","                  continue\n","            else:\n","                  edges_added.append(value)\n","                  nodelist[int(nodedict[value])].neighbors.append(nodelist[int(nodedict[key])])\n","                  nodelist[int(nodedict[key])].neighbors.append(nodelist[int(nodedict[value])])\n","\n","    # Write out the graph\n","    for node in nodelist:\n","        node_list_file.write(\"%s\\t%s\\t%s\\n\" % (node.id, node.name, node.type))\n","        adjlist_file.write(\"%s \" % node.id)\n","        for n in node.neighbors:\n","            adjlist_file.write(\"%s \" % n.id)\n","        adjlist_file.write(\"\\n\")\n","    adjlist_file.close()\n","    node_list_file.close()\n","    \n","    return nodedict\n"],"metadata":{"id":"V5_mcRtirj2f","executionInfo":{"status":"ok","timestamp":1657961548721,"user_tz":-330,"elapsed":340,"user":{"displayName":"ASHWIN SATHISH KUMAR","userId":"16573036374703807472"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["class Graph(defaultdict):\n","  \"\"\"Efficient basic implementation of nx `Graph' â€“ Undirected graphs with self loops\"\"\"  \n","  def __init__(self):\n","    super(Graph, self).__init__(list)\n","\n","  def nodes(self):\n","    return self.keys()\n","\n","  def adjacency_iter(self):\n","    return self.iteritems()\n","\n","  def subgraph(self, nodes={}):\n","    subgraph = Graph()\n","    \n","    for n in nodes:\n","      if n in self:\n","        subgraph[n] = [x for x in self[n] if x in nodes]\n","        \n","    return subgraph\n","\n","  def make_undirected(self):\n","  \n","    t0 = time()\n","\n","    for v in self.keys():\n","      for other in self[v]:\n","        if v != other:\n","          self[other].append(v)\n","    \n","    t1 = time()\n","    logger.info('make_directed: added missing edges {}s'.format(t1-t0))\n","\n","    self.make_consistent()\n","    return self\n","\n","  def make_consistent(self):\n","    t0 = time()\n","    for k in iterkeys(self):\n","      self[k] = list(sorted(set(self[k])))\n","    \n","    t1 = time()\n","    logger.info('make_consistent: made consistent in {}s'.format(t1-t0))\n","\n","    self.remove_self_loops()\n","\n","    return self\n","\n","  def remove_self_loops(self): \n","\n","    removed = 0\n","    t0 = time()\n","\n","    for x in self:\n","      if x in self[x]: \n","        self[x].remove(x)\n","        removed += 1\n","    \n","    t1 = time()\n","\n","    logger.info('remove_self_loops: removed {} loops in {}s'.format(removed, (t1-t0)))\n","    return self\n","\n","  def check_self_loops(self):\n","    for x in self:\n","      for y in self[x]:\n","        if x == y:\n","          return True\n","    \n","    return False\n","\n","  def has_edge(self, v1, v2):\n","    if v2 in self[v1] or v1 in self[v2]:\n","      return True\n","    return False\n","\n","  def degree(self, nodes=None):\n","    if isinstance(nodes, Iterable):\n","      return {v:len(self[v]) for v in nodes}\n","    else:\n","      return len(self[nodes])\n","\n","  def order(self):\n","    \"Returns the number of nodes in the graph\"\n","    return len(self)    \n","\n","  def number_of_edges(self):\n","    \"Returns the number of nodes in the graph\"\n","    return sum([self.degree(x) for x in self.keys()])/2\n","\n","  def number_of_nodes(self):\n","    \"Returns the number of nodes in the graph\"\n","    return OrderedDict()\n","\n","  def random_walk(self, path_length, alpha=0, rand=random.Random(), start=None):\n","    \"\"\" Returns a truncated random walk.\n","\n","        path_length: Length of the random walk.\n","        alpha: probability of restarts.\n","        start: the start node of the random walk.\n","    \"\"\"\n","    G = self\n","    if start:\n","      path = [start]\n","    else:\n","      # Sampling is uniform w.r.t V, and not w.r.t E\n","      path = [rand.choice(G.keys())]\n","\n","    while len(path) < path_length:\n","      cur = path[-1]\n","      if len(G[cur]) > 0:\n","        if rand.random() >= alpha:\n","          path.append(rand.choice(G[cur]))\n","        else:\n","          path.append(path[0])\n","      else:\n","        break\n","    return path"],"metadata":{"id":"LLRkVL5Mrj4l","executionInfo":{"status":"ok","timestamp":1657964394574,"user_tz":-330,"elapsed":397,"user":{"displayName":"ASHWIN SATHISH KUMAR","userId":"16573036374703807472"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# TODO add build_walks in here\n","def build_deepwalk_corpus(G, num_paths, path_length, alpha=0,\n","                      rand=random.Random(0)):\n","  walks = []\n","\n","  nodes = list(G.nodes())\n","  \n","  for cnt in range(num_paths):\n","    rand.shuffle(nodes)\n","    for node in nodes:\n","      walks.append(G.random_walk(path_length, rand=rand, alpha=alpha, start=node))\n","  \n","  return walks"],"metadata":{"id":"qUGwwNierj6q","executionInfo":{"status":"ok","timestamp":1657964401869,"user_tz":-330,"elapsed":366,"user":{"displayName":"ASHWIN SATHISH KUMAR","userId":"16573036374703807472"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def build_deepwalk_corpus_iter(G, num_paths, path_length, alpha=0,\n","                      rand=random.Random(0)):\n","  walks = []\n","\n","  nodes = list(G.nodes())\n","\n","  for cnt in range(num_paths):\n","    rand.shuffle(nodes)\n","    for node in nodes:\n","      yield G.random_walk(path_length, rand=rand, alpha=alpha, start=node)"],"metadata":{"id":"vSpgWJd_rj8B","executionInfo":{"status":"ok","timestamp":1657964413205,"user_tz":-330,"elapsed":330,"user":{"displayName":"ASHWIN SATHISH KUMAR","userId":"16573036374703807472"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["def clique(size): # a clique of a graph G is an induced subgraph of G that is complete.\n","    return from_adjlist(permutations(range(1,size+1)))"],"metadata":{"id":"ZqTmFZlprj_-","executionInfo":{"status":"ok","timestamp":1657964555868,"user_tz":-330,"elapsed":351,"user":{"displayName":"ASHWIN SATHISH KUMAR","userId":"16573036374703807472"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# http://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks-in-python\n","def grouper(n, iterable, padvalue=None):\n","    \"grouper(3, 'abcdefg', 'x') --> ('a','b','c'), ('d','e','f'), ('g','x','x')\"\n","    return zip_longest(*[iter(iterable)]*n, fillvalue=padvalue)"],"metadata":{"id":"gmhCnnhnrkDR","executionInfo":{"status":"ok","timestamp":1657964557456,"user_tz":-330,"elapsed":321,"user":{"displayName":"ASHWIN SATHISH KUMAR","userId":"16573036374703807472"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def parse_adjacencylist(f):\n","  adjlist = []\n","  for l in f:\n","    if l and l[0] != \"#\":\n","      introw = [int(x) for x in l.strip().split()]\n","      row = [introw[0]]\n","      row.extend(set(sorted(introw[1:])))\n","      adjlist.extend([row])\n","  \n","  return adjlist"],"metadata":{"id":"Dz1OqjbArkI1","executionInfo":{"status":"ok","timestamp":1657964559256,"user_tz":-330,"elapsed":333,"user":{"displayName":"ASHWIN SATHISH KUMAR","userId":"16573036374703807472"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["def parse_adjacencylist_unchecked(f):\n","  adjlist = []\n","  for l in f:\n","    if l and l[0] != \"#\":\n","      adjlist.extend([[int(x) for x in l.strip().split()]])\n","  \n","  return adjlist"],"metadata":{"id":"V1XdQvXOrkLF","executionInfo":{"status":"ok","timestamp":1657965489976,"user_tz":-330,"elapsed":461,"user":{"displayName":"ASHWIN SATHISH KUMAR","userId":"16573036374703807472"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["def load_adjacencylist(file_, undirected=False, chunksize=10000, unchecked=True):\n","\n","  if unchecked:\n","    parse_func = parse_adjacencylist_unchecked\n","    convert_func = from_adjlist_unchecked\n","  else:\n","    parse_func = parse_adjacencylist\n","    convert_func = from_adjlist\n","\n","  adjlist = []\n","\n","  t0 = time()\n","\n","  with open(file_) as f:\n","    with ProcessPoolExecutor(max_workers=cpu_count()) as executor:\n","      total = 0 \n","      for idx, adj_chunk in enumerate(executor.map(parse_func, grouper(int(chunksize), f))):\n","          adjlist.extend(adj_chunk)\n","          total += len(adj_chunk)\n","  \n","  t1 = time()\n","\n","  logger.info('Parsed {} edges with {} chunks in {}s'.format(total, idx, t1-t0))\n","\n","  t0 = time()\n","  G = convert_func(adjlist)\n","  t1 = time()\n","\n","  logger.info('Converted edges to graph in {}s'.format(t1-t0))\n","\n","  if undirected:\n","    t0 = time()\n","    G = G.make_undirected()\n","    t1 = time()\n","    logger.info('Made graph undirected in {}s'.format(t1-t0))\n","\n","  return G \n","\n","\n","def load_edgelist(file_, undirected=True):\n","  G = Graph()\n","  with open(file_) as f:\n","    for l in f:\n","      x, y = l.strip().split()[:2]\n","      x = int(x)\n","      y = int(y)\n","      G[x].append(y)\n","      if undirected:\n","        G[y].append(x)\n","  \n","  G.make_consistent()\n","  return G"],"metadata":{"id":"mqw546dlrkNc","executionInfo":{"status":"ok","timestamp":1657965597474,"user_tz":-330,"elapsed":342,"user":{"displayName":"ASHWIN SATHISH KUMAR","userId":"16573036374703807472"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["def load_matfile(file_, variable_name=\"network\", undirected=True):\n","  mat_varables = loadmat(file_)\n","  mat_matrix = mat_varables[variable_name]\n","\n","  return from_numpy(mat_matrix, undirected)"],"metadata":{"id":"8UapoKP6sonG","executionInfo":{"status":"ok","timestamp":1657965687935,"user_tz":-330,"elapsed":342,"user":{"displayName":"ASHWIN SATHISH KUMAR","userId":"16573036374703807472"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["def from_networkx(G_input, undirected=True):\n","    G = Graph()\n","\n","    for idx, x in enumerate(G_input.nodes_iter()):\n","        for y in iterkeys(G_input[x]):\n","            G[x].append(y)\n","\n","    if undirected:\n","        G.make_undirected()\n","\n","    return G"],"metadata":{"id":"yN7sC4sssooU","executionInfo":{"status":"ok","timestamp":1657965699135,"user_tz":-330,"elapsed":329,"user":{"displayName":"ASHWIN SATHISH KUMAR","userId":"16573036374703807472"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["def from_numpy(x, undirected=True):\n","    G = Graph()\n","\n","    if issparse(x):\n","        cx = x.tocoo()\n","        for i,j,v in zip(cx.row, cx.col, cx.data):\n","            G[i].append(j)\n","    else:\n","      raise Exception(\"Dense matrices not yet supported.\")\n","\n","    if undirected:\n","        G.make_undirected()\n","\n","    G.make_consistent()\n","    return G"],"metadata":{"id":"iNctncCYsop4","executionInfo":{"status":"ok","timestamp":1657965725229,"user_tz":-330,"elapsed":353,"user":{"displayName":"ASHWIN SATHISH KUMAR","userId":"16573036374703807472"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["def from_adjlist(adjlist):\n","    G = Graph()\n","    \n","    for row in adjlist:\n","        node = row[0]\n","        neighbors = row[1:]\n","        G[node] = list(sorted(set(neighbors)))\n","\n","    return G\n","\n","\n","def from_adjlist_unchecked(adjlist):\n","    G = Graph()\n","    \n","    for row in adjlist:\n","        node = str(row[0])\n","        neighbors = map(str, row[1:])\n","        G[node] = neighbors\n","\n","    return G"],"metadata":{"id":"aqKucY9Nsosa","executionInfo":{"status":"ok","timestamp":1657965728182,"user_tz":-330,"elapsed":556,"user":{"displayName":"ASHWIN SATHISH KUMAR","userId":"16573036374703807472"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["## walks.py"],"metadata":{"id":"Rq056cv5tm9K"}},{"cell_type":"code","source":["pip install deepwalk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":616},"id":"yuRuxsDgdia8","executionInfo":{"status":"ok","timestamp":1657965797273,"user_tz":-330,"elapsed":8291,"user":{"displayName":"ASHWIN SATHISH KUMAR","userId":"16573036374703807472"}},"outputId":"d0ff5805-167e-4438-92ae-0d7301913129"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting deepwalk\n","  Downloading deepwalk-1.0.3-py2.py3-none-any.whl (10 kB)\n","Requirement already satisfied: Cython>=0.20.2 in /usr/local/lib/python3.7/dist-packages (from deepwalk) (0.29.30)\n","Requirement already satisfied: psutil>=2.1.1 in /usr/local/lib/python3.7/dist-packages (from deepwalk) (5.4.8)\n","Requirement already satisfied: scipy>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from deepwalk) (1.7.3)\n","Requirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from deepwalk) (0.37.1)\n","Collecting argparse>=1.2.1\n","  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n","Requirement already satisfied: six>=1.7.3 in /usr/local/lib/python3.7/dist-packages (from deepwalk) (1.15.0)\n","Collecting futures>=2.1.6\n","  Downloading futures-3.0.5.tar.gz (25 kB)\n","\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/55/db/97c1ca37edab586a1ae03d6892b6633d8eaa23b23ac40c7e5bbc55423c78/futures-3.0.5.tar.gz#sha256=0542525145d5afc984c88f914a0c85c77527f65946617edb5274f72406f981df (from https://pypi.org/simple/futures/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n","  Downloading futures-3.0.4.tar.gz (25 kB)\n","\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/8d/73/b5fff618482bc06c9711e7cdc0d5d7eb1904d35898f48f2d7f9696b08bef/futures-3.0.4.tar.gz#sha256=19485d83f7bd2151c0aeaf88fbba3ee50dadfb222ffc3b66a344ef4952b782a3 (from https://pypi.org/simple/futures/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n","  Downloading futures-3.0.3.tar.gz (24 kB)\n","\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/4c/dc/f9473006d4c9c52d4a4e977173fbcbfb1a8ef3a57e32e885edf994fd4a45/futures-3.0.3.tar.gz#sha256=2fe2342bb4fe8b8e217f0d21b5921cbe5408bf966d9f92025e707e881b198bed (from https://pypi.org/simple/futures/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n","  Downloading futures-3.0.2.tar.gz (24 kB)\n","\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/f8/e7/fc0fcbeb9193ba2d4de00b065e7fd5aecd0679e93ce95a07322b2b1434f4/futures-3.0.2.tar.gz#sha256=dc3fc91508e49e0fd2f8625f0132d16e49c80f882e7e1d565c56b0d5dfbae257 (from https://pypi.org/simple/futures/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n","  Downloading futures-3.0.1.tar.gz (24 kB)\n","\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/b2/2c/6b6a57379e47031c6f52e625e0e2b8f6702a8d1f61b6e0daee391e82c187/futures-3.0.1.tar.gz#sha256=f78f2ef458639d72a625cf9c7643cf5442bb222ac11c12bcc445c6ad1cd862e2 (from https://pypi.org/simple/futures/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n","  Downloading futures-3.0.0.tar.gz (24 kB)\n","\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/ea/c9/35287369718fc05059e7a9d0d73c53745fe981010b4185b3858e7d46eff1/futures-3.0.0.tar.gz#sha256=d9cd7bb09aa01f0e4940af64c31fbd7045098b7b4354420d7838ea39e8b86ee3 (from https://pypi.org/simple/futures/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n","  Downloading futures-2.2.0-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: gensim>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from deepwalk) (3.6.0)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim>=1.0.0->deepwalk) (1.21.6)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=1.0.0->deepwalk) (5.2.1)\n","Installing collected packages: futures, argparse, deepwalk\n","Successfully installed argparse-1.4.0 deepwalk-1.0.3 futures-2.2.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["argparse","concurrent"]}}},"metadata":{}}]},{"cell_type":"code","source":["import logging\n","from io import open\n","from os import path\n","from time import time\n","from multiprocessing import cpu_count\n","import random\n","from concurrent.futures import ProcessPoolExecutor\n","from collections import Counter\n","\n","from six.moves import zip\n","\n","from deepwalk import graph"],"metadata":{"id":"_QRlA4-Wsoug","executionInfo":{"status":"ok","timestamp":1657965801354,"user_tz":-330,"elapsed":338,"user":{"displayName":"ASHWIN SATHISH KUMAR","userId":"16573036374703807472"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["logger = logging.getLogger(\"deepwalk\")\n","\n","__current_graph = None\n","\n","# speed up the string encoding\n","__vertex2str = None"],"metadata":{"id":"98j5lvtZsow4","executionInfo":{"status":"ok","timestamp":1657965805552,"user_tz":-330,"elapsed":317,"user":{"displayName":"ASHWIN SATHISH KUMAR","userId":"16573036374703807472"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["def count_words(file):\n","  \"\"\" Counts the word frequences in a list of sentences.\n","\n","  Note:\n","    This is a helper function for parallel execution of `Vocabulary.from_text`\n","    method.\n","  \"\"\"\n","  c = Counter()\n","  with open(file, 'r') as f:\n","    for l in f:\n","      words = l.strip().split()\n","      c.update(words)\n","  return c"],"metadata":{"id":"oerLIitdtMZU","executionInfo":{"status":"ok","timestamp":1657965808835,"user_tz":-330,"elapsed":320,"user":{"displayName":"ASHWIN SATHISH KUMAR","userId":"16573036374703807472"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["def count_textfiles(files, workers=1):\n","  c = Counter()\n","  with ProcessPoolExecutor(max_workers=workers) as executor:\n","    for c_ in executor.map(count_words, files):\n","      c.update(c_)\n","  return c"],"metadata":{"id":"sY-LTTb7tMbF","executionInfo":{"status":"ok","timestamp":1657965818652,"user_tz":-330,"elapsed":3,"user":{"displayName":"ASHWIN SATHISH KUMAR","userId":"16573036374703807472"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["def count_lines(f):\n","  if path.isfile(f):\n","    num_lines = sum(1 for line in open(f))\n","    return num_lines\n","  else:\n","    return 0"],"metadata":{"id":"QgdHaLUstMdV","executionInfo":{"status":"ok","timestamp":1657967325935,"user_tz":-330,"elapsed":375,"user":{"displayName":"ASHWIN SATHISH KUMAR","userId":"16573036374703807472"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["def _write_walks_to_disk(args):\n","  num_paths, path_length, alpha, rand, f = args\n","  G = __current_graph\n","  t_0 = time()\n","  with open(f, 'w') as fout:\n","    for walk in graph.build_deepwalk_corpus_iter(G=G, num_paths=num_paths, path_length=path_length,\n","                                                 alpha=alpha, rand=rand):\n","      fout.write(u\"{}\\n\".format(u\" \".join(__vertex2str[v] for v in walk)))\n","  logger.debug(\"Generated new file {}, it took {} seconds\".format(f, time() - t_0))\n","  return f"],"metadata":{"id":"LJ9NRx3QtMfU","executionInfo":{"status":"ok","timestamp":1657967327663,"user_tz":-330,"elapsed":2,"user":{"displayName":"ASHWIN SATHISH KUMAR","userId":"16573036374703807472"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["def write_walks_to_disk(G, filebase, num_paths, path_length, alpha=0, rand=random.Random(0), num_workers=cpu_count(),\n","                        always_rebuild=True):\n","  global __current_graph\n","  global __vertex2str\n","  __current_graph = G\n","  __vertex2str = {v:str(v) for v in G.nodes()}\n","  files_list = [\"{}.{}\".format(filebase, str(x)) for x in xrange(num_paths)]\n","  expected_size = len(G)\n","  args_list = []\n","  files = []\n","\n","  if num_paths <= num_workers:\n","    paths_per_worker = [1 for x in range(num_paths)]\n","  else:\n","    paths_per_worker = [len(filter(lambda z: z!= None, [y for y in x]))\n","                        for x in graph.grouper(int(num_paths / num_workers)+1, range(1, num_paths+1))]\n","\n","  with ProcessPoolExecutor(max_workers=num_workers) as executor:\n","    for size, file_, ppw in zip(executor.map(count_lines, files_list), files_list, paths_per_worker):\n","      if always_rebuild or size != (ppw*expected_size):\n","        args_list.append((ppw, path_length, alpha, random.Random(rand.randint(0, 2**31)), file_))\n","      else:\n","        files.append(file_)\n","\n","  with ProcessPoolExecutor(max_workers=num_workers) as executor:\n","    for file_ in executor.map(_write_walks_to_disk, args_list):\n","      files.append(file_)\n","\n","  return files"],"metadata":{"id":"v0s0Opl6tMhs","executionInfo":{"status":"ok","timestamp":1657967329636,"user_tz":-330,"elapsed":314,"user":{"displayName":"ASHWIN SATHISH KUMAR","userId":"16573036374703807472"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["def combine_files_iter(file_list):\n","  for file in file_list:\n","    with open(file, 'r') as f:\n","      for line in f:\n","        yield line.split()"],"metadata":{"id":"h0hWcV8VtMjr","executionInfo":{"status":"ok","timestamp":1657967332496,"user_tz":-330,"elapsed":322,"user":{"displayName":"ASHWIN SATHISH KUMAR","userId":"16573036374703807472"}}},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":["## skipgram.py"],"metadata":{"id":"jsFdpbE8uBg1"}},{"cell_type":"code","source":["from collections import Counter, Mapping\n","from concurrent.futures import ProcessPoolExecutor\n","import logging\n","from multiprocessing import cpu_count\n","from six import string_types\n","\n","from gensim.models import Word2Vec\n","from gensim.models.word2vec import Vocab"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VP_0G89HuGK3","executionInfo":{"status":"ok","timestamp":1657967335139,"user_tz":-330,"elapsed":1125,"user":{"displayName":"ASHWIN SATHISH KUMAR","userId":"16573036374703807472"}},"outputId":"dc7d9e77-2604-4190-9ac0-c42e4d6eb053"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n","  \"\"\"Entry point for launching an IPython kernel.\n"]}]},{"cell_type":"code","source":["logger = logging.getLogger(\"deepwalk\")"],"metadata":{"id":"03JgEHcSuGMi","executionInfo":{"status":"ok","timestamp":1657967338539,"user_tz":-330,"elapsed":350,"user":{"displayName":"ASHWIN SATHISH KUMAR","userId":"16573036374703807472"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["class Skipgram(Word2Vec):\n","    \"\"\"A subclass to allow more customization of the Word2Vec internals.\"\"\"\n","\n","    def __init__(self, vocabulary_counts=None, **kwargs):\n","\n","        self.vocabulary_counts = None\n","\n","        kwargs[\"min_count\"] = kwargs.get(\"min_count\", 1)\n","        kwargs[\"workers\"] = kwargs.get(\"workers\", cpu_count())\n","        kwargs[\"size\"] = kwargs.get(\"size\", 128)\n","        kwargs[\"sentences\"] = kwargs.get(\"sentences\", None)\n","\n","        if vocabulary_counts != None:\n","          self.vocabulary_counts = vocabulary_counts\n","\n","        super(Skipgram, self).__init__(**kwargs)\n","\n","    def build_vocab(self, corpus):\n","        \"\"\"\n","        Build vocabulary from a sequence of sentences or from a frequency dictionary, if one was provided.\n","        \"\"\"\n","        if self.vocabulary_counts != None:\n","          logger.debug(\"building vocabulary from provided frequency map\")\n","          vocab = self.vocabulary_counts\n","        else:\n","          logger.debug(\"default vocabulary building\")\n","          super(Skipgram, self).build_vocab(corpus)\n","          return\n","\n","        # assign a unique index to each word\n","        self.vocab, self.index2word = {}, []\n","\n","        for word, count in vocab.iteritems():\n","            v = Vocab()\n","            v.count = count\n","            if v.count >= self.min_count:\n","                v.index = len(self.vocab)\n","                self.index2word.append(word)\n","                self.vocab[word] = v\n","\n","        logger.debug(\"total %i word types after removing those with count<%s\" % (len(self.vocab), self.min_count))\n","\n","        if self.hs:\n","            # add info about each word's Huffman encoding\n","            self.create_binary_tree()\n","        if self.negative:\n","            # build the table for drawing random words (for negative sampling)\n","            self.make_table()\n","        # precalculate downsampling thresholds\n","        self.precalc_sampling()\n","        self.reset_weights()"],"metadata":{"id":"fn3K7wFCuGO7","executionInfo":{"status":"ok","timestamp":1657967340404,"user_tz":-330,"elapsed":366,"user":{"displayName":"ASHWIN SATHISH KUMAR","userId":"16573036374703807472"}}},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":["## main.py"],"metadata":{"id":"VjD7fSwgtjlj"}},{"cell_type":"code","source":["import sys\n","import random\n","from gensim.models import Word2Vec\n","from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter\n","from time import time\n","import numpy as np\n","from sklearn.metrics import confusion_matrix, accuracy_score, mean_squared_error"],"metadata":{"id":"y0ykvzIftMmn","executionInfo":{"status":"ok","timestamp":1657967357601,"user_tz":-330,"elapsed":336,"user":{"displayName":"ASHWIN SATHISH KUMAR","userId":"16573036374703807472"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["def process(args):\n","    # Create a graph from the training set\n","    nodedict = records_to_graph()\n","\n","    # Build the model using DeepWalk and Word2Vec\n","    G = load_adjacencylist(\"out.adj\", undirected=True)\n","    \n","    walks = build_deepwalk_corpus(G,int(args.number_walks),int(args.walk_length))\n","    model = Word2Vec(walks,100,5,5,1)\n","                     \n","    # Perform some evaluation of the model on the test dataset\n","    with open(\"./data/test_user_ratings.dat\") as fin:\n","        fin.next()\n","        groundtruth = [line.strip().split(\"\\t\")[:3] for line in fin]    # (user, movie, rating)\n","    tr = [int(round(float(g[2]))) for g in groundtruth]\n","    pr = [predict_rating(model, nodedict, \"u\"+g[0], \"m\"+g[1]) for g in groundtruth]\n","\n","    print (\"MSE = %f\" % mean_squared_error(tr, pr))\n","    print (\"accuracy = %f\" % accuracy_score(tr, pr))\n","    cm = confusion_matrix(tr, pr, labels=range(1,6))\n","    print (cm)"],"metadata":{"id":"fJnwTgZAtMo-","executionInfo":{"status":"ok","timestamp":1657967380550,"user_tz":-330,"elapsed":493,"user":{"displayName":"ASHWIN SATHISH KUMAR","userId":"16573036374703807472"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["def predict_rating(model, nodedict, user, movie):\n","    \"\"\"\n","    Predicts the rating between a user and a movie by finding the movie-rating node with the highest\n","    similarity to the given user node.\n","    Loops through the five possible movie-rating nodes and finds the node with the highest similarity to the user.\n","    \n","    Returns an integer rating 1-5.\n","    \"\"\"\n","    \n","    i, minimum_value = 1, 1\n","    val = movie + '_' + str(i)\n","    minimum_sim = model.similarity(str(nodedict[val]), str(nodedict[user]))\n","    while i < 5:\n","        i += 1\n","        val = movie + '_' + str(i)\n","        sim = model.similarity(str(nodedict[val]), str(nodedict[user]))\n","        if (sim < minimum_sim):\n","            minimum_sim = sim\n","            minimum_value = i\n","    return minimum_value"],"metadata":{"id":"FS4BuFNatMrE","executionInfo":{"status":"ok","timestamp":1657967385427,"user_tz":-330,"elapsed":556,"user":{"displayName":"ASHWIN SATHISH KUMAR","userId":"16573036374703807472"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["def main():\n","    parser = ArgumentParser(\"rec2vec\", \n","        formatter_class=ArgumentDefaultsHelpFormatter,\n","        conflict_handler='resolve')\n","    parser.add_argument('--number-walks', default=10, type=int,\n","        help='Number of random walks to start at each node')\n","    parser.add_argument('--walk-length', default=40, type=int,\n","        help='Length of the random walk started at each node')\n","    parser.add_argument('--seed', default=0, type=int,\n","        help='Seed for random walk generator.')   \n","    parser.add_argument('--max-memory-data-size', default=1000000000, type=int,\n","        help='Size to start dumping walks to disk, instead of keeping them in memory.')\n","    parser.add_argument('--window-size', default=5, type=int,\n","        help='Window size of skipgram model.')\n","    parser.add_argument('--workers', default=1, type=int,\n","        help='Number of parallel processes.')        \n","    parser.add_argument('--representation-size', default=64, type=int,\n","        help='Number of latent dimensions to learn for each node.')\n","    \n","    parser.set_defaults(csv_to_graph=True, loo=True)\n","    args = parser.parse_args()\n","    \n","    process(args)\n","    \n","\n","if __name__==\"__main__\":\n","    sys.exit(main())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":252},"id":"xJfQdZd3trqs","executionInfo":{"status":"error","timestamp":1657967388258,"user_tz":-330,"elapsed":327,"user":{"displayName":"ASHWIN SATHISH KUMAR","userId":"16573036374703807472"}},"outputId":"29d2de3e-27e1-4458-d436-334774e79788"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stderr","text":["usage: rec2vec [-h] [--number-walks NUMBER_WALKS] [--walk-length WALK_LENGTH]\n","               [--seed SEED] [--max-memory-data-size MAX_MEMORY_DATA_SIZE]\n","               [--window-size WINDOW_SIZE] [--workers WORKERS]\n","               [--representation-size REPRESENTATION_SIZE]\n","rec2vec: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-b4842ab2-9232-4d05-aa31-0fd0e3f0a31a.json\n"]},{"output_type":"error","ename":"SystemExit","evalue":"ignored","traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n","  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"iVn6Ta11trsQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"Rq9NJf2ntrui"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"od-WNdA9trw0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"FNydRGtCtrzV"},"execution_count":null,"outputs":[]}]}